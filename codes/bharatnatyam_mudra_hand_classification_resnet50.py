# -*- coding: utf-8 -*-
"""Bharatnatyam_mudra_hand_classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y6YBozWQWWK-b9DhP5S6VYqyUXAjmdzT
"""

from google.colab import drive
drive.mount('/content/drive')

!scp /content/drive/MyDrive/bht_mudra_hands.zip ./
!unzip bht_mudra_hands

path = "/content/bht_mudra_hands/"

import shutil
import os

files = os.listdir(path)
# print(files)
mudras=[]
for file in files:
  mudras.append(file.split('_')[0])

mudras=list(set(mudras))
m1=[]
for mudra in mudras:
  m1.append(mudra.strip())
mudras=m1
mudras.sort()
print(mudras)

single_hand=['Pathaka', 'Tripathaka','Ardhapathaka','Mayura','Katrimukha','Ardhachandran','Aralam',
             'Shukatundam','Mushti','Sikharam','Kapith','Katakamukha 1','Katakamukha 2','Katakamukha 3',
             'Suchi','Chandrakala','Padmakosha','Sarpasirsha','Mrigasirsha','Simhamukham','Kangulam',
             'Alapadmam','Mukulam','Chaturam','Bramaram','Hamsasyam','Hamsapaksha','Tamarachudam','Trishulam']

double_hand=['Anjali','Kapotham','Karkatta','Swastikam','Pushpaputa','Shivalinga','Katakavardhana',
             'Kartariswastika','Sakata','Shanka','Chakra','Samputa','Pasha','Kilaka','Matsya','Kurma',
             'Varaha','Garuda','Nagabandha','Khatva','Berunda']    

# print(len(single_hand)+len(double_hand))

hand_map=dict()

f=0
for i in single_hand:  #0-28 for single hand
  hand_map[i]=f
  f+=1

for i in double_hand: # 29-49 for double hand
  hand_map[i]=f
  f+=1
print(hand_map)

dataset=[]
# for i in range(50):
#   dataset.append([])

for file in os.listdir(path):
  # try:
    f_name=file.split('_')[0]
    f_name=f_name.strip()
    f_name=f_name.replace('\u200b','')
    # f_name=f_name.strip('\u200b')
    # dataset[hand_map[f_name]].append([f_name,path+file])
    dataset.append([f_name,path+file])


print(dataset[0:5])

import pandas as pd
import numpy as np
Mudras_df = pd.DataFrame(dataset)
Mudras_df.columns = ['mudra', 'path']


    
print('Bharatnatayam Mudra datasets')
Mudras_df.head()

from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.model_selection import train_test_split


mudra_X = Mudras_df['path'].values
mudra_Y = Mudras_df['mudra'].values

# print(mudra_X)
# print(mudra_Y)

x_train,x_test,y_train,y_test=train_test_split(mudra_X,mudra_Y,random_state=0,test_size=0.20,shuffle=True)

print(x_train)
print(x_test)
print(y_train)
print(y_test)

import cv2
X=[]
Y=[]
for path,label in zip(mudra_X,mudra_Y):
  img=cv2.imread(path) #reads image and return np array
  # img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
  img=cv2.resize(img,(320,120))
  X.append(img)
  Y.append(hand_map[label])

print(len(X[0]),len(X))
print(Y)

x1=X
y1=Y

X=np.array(X,dtype="uint8")
X=X.reshape(len(mudra_X),120,320,3)
Y=np.array(Y)

from sklearn.model_selection import train_test_split
# X = pd.DataFrame(X)
X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3,random_state=42)

print(X_test.shape)

# import tensorflow as tf
# import matplotlib.pyplot as plt
# from tensorflow.keras import datasets, layers, models, losses, Model

# base_model = tf.keras.applications.ResNet152(include_top = False, input_shape = (120,320,3))
# for layer in base_model.layers:
#   layer.trainable = False

# x = layers.Flatten()(base_model.output)
# x = layers.Dense(1000, activation='relu')(x)
# predictions = layers.Dense(50, activation = 'softmax')(x)

# head_model = Model(inputs = base_model.input, outputs = predictions)
# head_model.compile(optimizer='adam', loss=losses.sparse_categorical_crossentropy, metrics=['accuracy'])

# print(x_train.shape)

import torch
import torchvision
import torch.utils.data as data
import torchvision.transforms as transforms
from torchvision import models
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import matplotlib.pyplot as plt

from PIL import Image

# print(path)
path = "/content/drive/MyDrive/bht_mudra_hands_class"

# for i,j in dataset:
#   try: 
#       os.mkdir('/content/drive/MyDrive/bht_mudra_hands_class/'+i) 
#       img = cv2.imread(j)
#       cv2.imwrite('/content/drive/MyDrive/bht_mudra_hands_class/'+i+'/'+j.split('/')[::-1][0],img)
#   except OSError as error: 
#       img = cv2.imread(j)
#       cv2.imwrite('/content/drive/MyDrive/bht_mudra_hands_class/'+i+'/'+j.split('/')[::-1][0],img)

transform = transforms.Compose([      transforms.ToTensor(),
                                      transforms.Normalize([0.5], [0.5])
                                     ])
dataset = torchvision.datasets.ImageFolder(root=path, transform=transform)
num_imgs = len(dataset)
print(num_imgs)
# Let's split the dataset as: train: 65%, val: 10%, test: 25%.
train_length = int(0.80*num_imgs)
val_length = int(0.1*num_imgs)
test_length = num_imgs - train_length - val_length
print(train_length, val_length, test_length)

train_set,val_set,test_set = data.random_split(dataset, [train_length, val_length, test_length])


# Define a set of data loaders
train_loader = data.DataLoader(train_set, batch_size=16, shuffle=True,drop_last=False, pin_memory=True, num_workers=1)
val_loader = data.DataLoader(val_set, batch_size=16, shuffle=False, drop_last=False, num_workers=1)
test_loader = data.DataLoader(test_set, batch_size=16, shuffle=False, drop_last=False, num_workers=1)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f'Using {device} for inference')

model =models.resnet50(2).to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.00001)

print(train_loader)

#train model
model.train()
for epoch in range(2):
  total_correct=0.0
  running_loss=0.0
  for i,inp in enumerate(train_loader):
    inputs, labels = inp
    inputs, labels = inputs.to(device), labels.to(device)
    output=model(inputs)
    output_idx=torch.argmax(output,dim=1)
    total_correct+=(labels==output_idx).sum().item()
    optimizer.zero_grad()
    loss = criterion(output, labels)
    running_loss+=loss.item()*inputs.size(0)
    loss.backward()
    optimizer.step()
  print(f'Epoch:{epoch}  loss:  {running_loss/train_length } Accuracy: {(total_correct/train_length)*100}%')

print('training done')

torch.save(model.state_dict(),'/content/drive/MyDrive/mtp.pt')

with torch.no_grad():
  model.eval()
  total_correct=0.0
  total_loss=0.0
  for inputs,labels in test_loader:
    
    labels = labels.to(device)
    outputs=model(inputs.to(device))
    loss=criterion(outputs,labels)
    total_loss+=loss.item()*inputs.size(0)
    output_idx=torch.argmax(outputs,dim=1)
    total_correct+=sum(labels==output_idx)

  print(f'Accuracy: {(total_correct/test_length)*100}% Loss:{total_loss/test_length}')

print('testing done')

# history = head_model.fit(X_train, Y_train, batch_size=64, epochs=40)